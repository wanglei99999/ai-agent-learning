{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG\n",
    "\n",
    "## 核心思想\n",
    "\n",
    "Agentic RAG 的核心不是使用更复杂的模型，而是**让模型使用 tools 完成任务**。\n",
    "\n",
    "和一次性把文档塞进 Prompt 就生成答案的 Native RAG 相比，Agentic RAG 让大模型扮演一个**决策-执行的控制器**。\n",
    "\n",
    "> 模型通过自主决策调用 tools 实现的 RAG 过程，就可以称为 Agentic RAG。无论这个过程是发生在重写 query、检索阶段或者精读阶段，只要有模型的自主决策过程，就可以称为 Agentic RAG。\n",
    "\n",
    "## 运行流程\n",
    "\n",
    "```\n",
    "User Query -> LLM (GPT/Claude/DeepSeek) <-> Tools (MCP Server)\n",
    "                    |                         ^\n",
    "              Use Tool ----------------------->\n",
    "                    <--------------- Tool Result\n",
    "                    |\n",
    "         Recycle until model decide response to user\n",
    "                    |\n",
    "               Response\n",
    "```\n",
    "\n",
    "**核心要点：Search Ability As a Tool**\n",
    "\n",
    "模型就可以通过可用的工具获取到想要的信息从而给出更合适的回复。\n",
    "\n",
    "## 与传统 RAG 的对比\n",
    "\n",
    "| 特性 | 传统 RAG | Agentic RAG |\n",
    "|------|----------|-------------|\n",
    "| 流程 | 一次性流水线 | 多轮迭代循环 |\n",
    "| Query 处理 | 直接使用原始 query | 可改写、分解、扩展 |\n",
    "| 检索策略 | 固定策略 | 动态选择 |\n",
    "| 结果评估 | 无 | Agent 评估相关性 |\n",
    "| 精读能力 | 无 | 可对文档深度理解 |\n",
    "| 决策主体 | 代码逻辑 | LLM 自主决策 |\n",
    "\n",
    "## 关键能力\n",
    "\n",
    "1. **Query 理解与改写**：Agent 分析用户意图，改写或分解复杂问题\n",
    "2. **多轮检索**：根据初次检索结果决定是否需要补充检索\n",
    "3. **结果评估**：评估检索结果的相关性，过滤低质量内容\n",
    "4. **Reason-Act-Observe 循环**：按需多轮调用工具\n",
    "\n",
    "## 实现方式\n",
    "\n",
    "本示例采用 **单 Agent + Tools** 模式（非 Subagent 模式）：\n",
    "- 1 个 LLM 作为大脑\n",
    "- 多个 Tools 封装 RAG 能力\n",
    "- Agent 自主决策调用哪个工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境初始化\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "qwen_plus_model = init_chat_model(\n",
    "    \"qwen-plus\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "#向量化\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "\n",
    "embeddings = DashScopeEmbeddings(\n",
    "    model=\"text-embedding-v2\",\n",
    "    dashscope_api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"./faiss_index\",\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import tool\n",
    "\n",
    "class expand_and_keyword_format(BaseModel):\n",
    "    \"\"\"对用户的query进行改写和提取关键词的结果\"\"\"\n",
    "    expand_query:str = Field(...,description =  \"对query进行扩写/改写的结果，可以不改写\")\n",
    "    keyword: str = Field(...,description = \"在query中提取一个最重要的简短关键字\")\n",
    "\n",
    "@tool\n",
    "def expand_and_keyword(query):\n",
    "    \"\"\"\n",
    "        对用户输入的query进行改写和提取一个最重要的关键字\n",
    "        :param query:str, 必填 -是用户的输入，在此基础上进行改写和提取关键字。\n",
    "        :return expand_query: str, 必填- 对用户query进行扩写/改写的结果，可以不改写\n",
    "        :return keyword：str,对用户的输入提取一个最重要的关键字。\n",
    "    \"\"\"\n",
    "\n",
    "    expand_and_keyword_conversation = [\n",
    "        {\"role\":\"system\",\"content\":\"你是一个乐于助人的助手，负责给用户的query进行改写/扩写，同时，在query中提取一个最重要的关键词\"},\n",
    "        {\"role\":\"user\",\"content\":query},\n",
    "    ]\n",
    "    #格式化输出这样更简单，不需要用agent的能力\n",
    "    model_with_structure = model.with_structure_output(expand_and_keyword_format)\n",
    "    response = model_with_structure.invoke(expand_and_keyword_conversation)\n",
    "    expand_query = response.expand_query\n",
    "    keyword = response.keyword\n",
    "    return expand_query,keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieval_augment(query,keyword):\n",
    "    \"\"\"\n",
    "        【rag检索增强】基于用户输入的查询语句和核心关键词，从知识库中检索相关文档并增强结果。\n",
    "        核心逻辑：先按query检索top10文档，若有keyword则调整匹配得分（含关键词的文档得分-0.1）,按照得分升序排序，拼接前5条文档内容返回。\n",
    "        :param query:str, 必填，用户输入的自然语言查询语句，作为基础检索条件。\n",
    "        :param keyword：str,必填，从用户输入中提取的核心关键词，用于优化检索结果权重。\n",
    "        :return related_doc: str, 按优化后得分排序库文档内容的检索结果，以双换行符分割拼接后的字符串 \n",
    "    \"\"\"\n",
    "    # 用 with_score 获取分数\n",
    "    docs = vectorstore.similarity_search_with_score(query,k=10)\n",
    "\n",
    "     # 如果有关键词，调整得分\n",
    "    if keyword:\n",
    "        adjusted = []\n",
    "        for doc, score in docs_with_scores:\n",
    "            if keyword in doc.page_content:\n",
    "                score -= 0.1  # 含关键词的得分更低（FAISS分数越低越相似）\n",
    "            adjusted.append((doc, score))\n",
    "        docs_with_scores = adjusted\n",
    "\n",
    "     \n",
    "    # 按分数升序排序（越小越相似）\n",
    "    docs_with_scores = sorted(docs_with_scores, key=lambda x: x[1])\n",
    "\n",
    "    top_docs = docs_with_scores[:5]\n",
    "    related_doc = '\\n\\n'.join([doc.page_content for doc, score in top_docs])\n",
    "    \n",
    "    return related_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class summary_related_doc_format(BaseModel):\n",
    "    '''\n",
    "        对用户的query相关的片段进行筛选\n",
    "    '''\n",
    "    summary_related_doc_res:str = Field(...,description = '对用户query相关的片段进行筛选')\n",
    "@tool\n",
    "def summary_related_doc(query,related_doc):\n",
    "    '''\n",
    "        片段精读。根据用户的query,在related_doc原始片段中把与query相关的片段进行摘取，不要进行改写，仅把相关部分进行筛选复制。\n",
    "\n",
    "        :param query:str ,必填，用户输入的自然语言查询语句，作为基础的检索条件\n",
    "        :param related_doc:str,必填，原始的文档片段\n",
    "        :return :summary_related_doc_res,筛选后的片段\n",
    "    '''\n",
    "\n",
    "    query_and_related_doc = f'这是用户的query:{query}\\n\\n这是原文的众多片段:{related_doc}'\n",
    "    summary_related_doc_conversation = [\n",
    "        {\"role\":\"system\",\"content\":\"你是一个乐于助人的助手，现在又很多原文片段，你需要对用户query相关的片段进行筛选，不要改动原文，只要把相关的片段进行复制筛选即可\"},\n",
    "        {\"role\":\"user\",\"content\":query_and_related_doc}\n",
    "    ]\n",
    "\n",
    "    model_with_structure = model.with_structure_output(summary_related_doc_format)\n",
    "    response = model_with_structure.invoke(summary_related_doc_conversation)\n",
    "    summary_related_doc_res = response.summary_related_doc_res\n",
    "    return summary_related_doc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''\n",
    "你是一名助人为乐的助手，你会根据用户的问题进行判断：\n",
    "\n",
    "- 如果用户问题与校规不相关，直接回答，不要调用工具。\n",
    "\n",
    "- 如果用户问题与校规相关，按以下步骤操作：\n",
    "  1. 调用 expand_and_keyword 改写问题、提取关键词\n",
    "  2. 调用 retrieval_augment 检索相关文档\n",
    "  3. 若检索结果过长，调用 summary_related_doc 精读筛选\n",
    "  4. 根据检索内容回答用户问题\n",
    "  5. 若未找到答案，可重试一次（最多两次）\n",
    "  6. 两次后仍无答案，回复：没有在文档中检索到相关内容\n",
    "\n",
    "回答时请基于检索到的文档内容，不要编造。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m tools = [expand_and_keyword, retrieval_augment, summary_related_doc]\n\u001b[32m      3\u001b[39m agent = create_agent(\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     model=\u001b[43mmodel\u001b[49m,\n\u001b[32m      5\u001b[39m     tools=tools,\n\u001b[32m      6\u001b[39m     system_prompt=system_prompt,\n\u001b[32m      7\u001b[39m     middleware=[\n\u001b[32m      8\u001b[39m         \u001b[38;5;66;03m# 全局限制：所有 tool 总共最多调用 10 次\u001b[39;00m\n\u001b[32m      9\u001b[39m         ToolCallLimitMiddleware(run_limit=\u001b[32m10\u001b[39m),\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m         \u001b[38;5;66;03m# 单个 tool 限制：每个 tool 最多调用 2 次\u001b[39;00m\n\u001b[32m     12\u001b[39m         ToolCallLimitMiddleware(tool_name=\u001b[33m\"\u001b[39m\u001b[33mexpand_and_keyword\u001b[39m\u001b[33m\"\u001b[39m, run_limit=\u001b[32m2\u001b[39m),\n\u001b[32m     13\u001b[39m         ToolCallLimitMiddleware(tool_name=\u001b[33m\"\u001b[39m\u001b[33mretrieval_augment\u001b[39m\u001b[33m\"\u001b[39m, run_limit=\u001b[32m2\u001b[39m),\n\u001b[32m     14\u001b[39m         ToolCallLimitMiddleware(tool_name=\u001b[33m\"\u001b[39m\u001b[33msummary_related_doc\u001b[39m\u001b[33m\"\u001b[39m, run_limit=\u001b[32m2\u001b[39m),\n\u001b[32m     15\u001b[39m     ]\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# 调用\u001b[39;00m\n\u001b[32m     20\u001b[39m response = agent.invoke({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m学生可以转专业吗\u001b[39m\u001b[33m\"\u001b[39m}]})\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "tools = [expand_and_keyword, retrieval_augment, summary_related_doc]\n",
    "\n",
    "agent = create_agent(\n",
    "    model=qwen_plus_model,\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt,\n",
    "    middleware=[\n",
    "        # 全局限制：所有 tool 总共最多调用 10 次\n",
    "        ToolCallLimitMiddleware(run_limit=10),\n",
    "        \n",
    "        # 单个 tool 限制：每个 tool 最多调用 2 次\n",
    "        ToolCallLimitMiddleware(tool_name=\"expand_and_keyword\", run_limit=2),\n",
    "        ToolCallLimitMiddleware(tool_name=\"retrieval_augment\", run_limit=2),\n",
    "        ToolCallLimitMiddleware(tool_name=\"summary_related_doc\", run_limit=2),\n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "# 调用\n",
    "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"学生可以转专业吗\"}]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试不相关问题\n",
    "query = '你是谁？'\n",
    "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
    "\n",
    "response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试相关的问题\n",
    "query = '两周未参加学校活动会被退学吗'\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]}\n",
    ")\n",
    "\n",
    "# 遍历所有消息，查看 Agent 的执行轨迹\n",
    "for res in response['messages']:\n",
    "    print(res.name, end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试不相关问题\n",
    "query = '如果想要换班级怎么走流程'\n",
    "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-learning",
   "language": "python",
   "name": "ai-agent-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
