# 短期记忆详解

记忆系统让 Agent 能够记住之前的交互、从反馈中学习，并适应用户偏好。随着 Agent 处理越来越复杂的任务和大量用户交互，这种能力变得至关重要。

短期记忆让应用能够在单个线程或对话中记住之前的交互。

> **线程（Thread）** 类似于邮件中的会话，将多个交互组织在一起。

对话历史是最常见的短期记忆形式。但长对话对当前的 LLM 来说是个挑战：完整的历史可能无法放入 LLM 的上下文窗口，导致上下文丢失或错误。

即使模型支持完整的上下文长度，大多数 LLM 在长上下文中表现仍然不佳——它们会被陈旧或离题的内容"分散注意力"，同时响应速度变慢、成本增加。

## 基本用法

要为 Agent 添加短期记忆（线程级持久化），需要在创建 Agent 时指定 `checkpointer`：

```python
from langchain.agents import create_agent
from langgraph.checkpoint.memory import InMemorySaver

agent = create_agent(
    "gpt-4o",
    tools=[get_user_info],
    checkpointer=InMemorySaver(),  # 启用短期记忆
)

# 使用 thread_id 标识对话
agent.invoke(
    {"messages": [{"role": "user", "content": "你好！我叫小明。"}]},
    {"configurable": {"thread_id": "1"}},  # 同一个 thread_id 共享记忆
)
```

**工作原理：**

- LangChain 的 Agent 将短期记忆作为状态的一部分管理
- 通过将状态存储在图的状态中，Agent 可以访问给定对话的完整上下文，同时保持不同线程之间的隔离
- 状态通过 checkpointer 持久化到数据库（或内存），因此线程可以随时恢复
- 当 Agent 被调用或某个步骤（如工具调用）完成时，短期记忆会更新；在每个步骤开始时读取状态

### 生产环境

在生产环境中，使用数据库支持的 checkpointer：

```bash
pip install langgraph-checkpoint-postgres
```

```python
from langchain.agents import create_agent
from langgraph.checkpoint.postgres import PostgresSaver

DB_URI = "postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable"

with PostgresSaver.from_conn_string(DB_URI) as checkpointer:
    checkpointer.setup()  # 自动在 PostgreSQL 中创建表
    
    agent = create_agent(
        "gpt-4o",
        tools=[get_user_info],
        checkpointer=checkpointer,
    )
```

## 自定义 Agent 记忆

默认情况下，Agent 使用 `AgentState` 管理短期记忆，通过 `messages` 键存储对话历史。

你可以扩展 `AgentState` 添加额外字段。自定义状态 schema 通过 `state_schema` 参数传递给 `create_agent`：

```python
from langchain.agents import create_agent, AgentState
from langgraph.checkpoint.memory import InMemorySaver

class CustomAgentState(AgentState):
    user_id: str           # 新增：用户 ID
    preferences: dict      # 新增：用户偏好

agent = create_agent(
    "gpt-4o",
    tools=[get_user_info],
    state_schema=CustomAgentState,  # 使用自定义状态
    checkpointer=InMemorySaver(),
)

# 调用时可以传入自定义状态
result = agent.invoke(
    {
        "messages": [{"role": "user", "content": "你好"}],
        "user_id": "user_123",              # 自定义字段
        "preferences": {"theme": "dark"}    # 自定义字段
    },
    {"configurable": {"thread_id": "1"}}
)
```

## 常见模式

启用短期记忆后，长对话可能超出 LLM 的上下文窗口。常见的解决方案：

| 方案 | 说明 |
|------|------|
| 裁剪消息 | 在调用 LLM 前移除前 N 条或后 N 条消息 |
| 删除消息 | 从 LangGraph 状态中永久删除消息 |
| 总结消息 | 总结早期消息并用摘要替换它们 |
| 自定义策略 | 消息过滤等自定义策略 |

这些方法让 Agent 能够跟踪对话而不超出 LLM 的上下文窗口。

### 裁剪消息

决定何时截断消息的一种方法是计算消息历史中的 token 数，并在接近限制时截断。

使用 `@before_model` 中间件装饰器在 Agent 中裁剪消息历史：

```python
from langchain.messages import RemoveMessage
from langgraph.graph.message import REMOVE_ALL_MESSAGES
from langgraph.checkpoint.memory import InMemorySaver
from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import before_model
from langgraph.runtime import Runtime
from langchain_core.runnables import RunnableConfig
from typing import Any

@before_model
def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
    """只保留最近几条消息以适应上下文窗口。"""
    messages = state["messages"]
    
    if len(messages) <= 3:
        return None  # 不需要修改
    
    # 保留第一条消息（通常是系统消息）
    first_msg = messages[0]
    # 保留最近的消息
    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]
    new_messages = [first_msg] + recent_messages
    
    return {
        "messages": [
            RemoveMessage(id=REMOVE_ALL_MESSAGES),
            *new_messages
        ]
    }

agent = create_agent(
    "gpt-4o",
    tools=[],
    middleware=[trim_messages],
    checkpointer=InMemorySaver(),
)

config: RunnableConfig = {"configurable": {"thread_id": "1"}}

agent.invoke({"messages": "你好，我叫小明"}, config)
agent.invoke({"messages": "写一首关于猫的短诗"}, config)
agent.invoke({"messages": "现在写一首关于狗的"}, config)
final_response = agent.invoke({"messages": "我叫什么名字？"}, config)

final_response["messages"][-1].pretty_print()
"""
================================== Ai Message ==================================
你叫小明。你之前告诉我的。
如果你想让我用昵称或其他名字称呼你，随时告诉我。
"""
```

### 删除消息

你可以从图状态中删除消息来管理消息历史。这在你想要移除特定消息或清除整个消息历史时很有用。

要使 `RemoveMessage` 生效，需要使用带有 `add_messages` reducer 的状态键。默认的 `AgentState` 已经提供了这个。

删除特定消息：

```python
from langchain.messages import RemoveMessage

def delete_messages(state):
    messages = state["messages"]
    if len(messages) > 2:
        # 移除最早的两条消息
        return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}
```

删除所有消息：

```python
from langgraph.graph.message import REMOVE_ALL_MESSAGES

def delete_messages(state):
    return {"messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}
```

> ⚠️ 删除消息时，**确保**生成的消息历史是有效的。检查你使用的 LLM 提供商的限制。例如：
> - 某些提供商要求消息历史以 `user` 消息开头
> - 大多数提供商要求带有工具调用的 `assistant` 消息后面跟着相应的 `tool` 结果消息

完整示例：

```python
from langchain.messages import RemoveMessage
from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import after_model
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.runtime import Runtime
from langchain_core.runnables import RunnableConfig

@after_model
def delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None:
    """删除旧消息以保持对话可管理。"""
    messages = state["messages"]
    if len(messages) > 2:
        # 移除最早的两条消息
        return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}
    return None

agent = create_agent(
    "gpt-4o-mini",
    tools=[],
    system_prompt="请简洁明了。",
    middleware=[delete_old_messages],
    checkpointer=InMemorySaver(),
)

config: RunnableConfig = {"configurable": {"thread_id": "1"}}

for event in agent.stream(
    {"messages": [{"role": "user", "content": "你好！我叫小明"}]},
    config,
    stream_mode="values",
):
    print([(message.type, message.content) for message in event["messages"]])

for event in agent.stream(
    {"messages": [{"role": "user", "content": "我叫什么名字？"}]},
    config,
    stream_mode="values",
):
    print([(message.type, message.content) for message in event["messages"]])
```

输出：
```
[('human', '你好！我叫小明')]
[('human', '你好！我叫小明'), ('ai', '你好小明！很高兴认识你。有什么我可以帮助你的吗？')]
[('human', '你好！我叫小明'), ('ai', '你好小明！很高兴认识你。有什么我可以帮助你的吗？'), ('human', '我叫什么名字？')]
[('human', '你好！我叫小明'), ('ai', '你好小明！很高兴认识你。有什么我可以帮助你的吗？'), ('human', '我叫什么名字？'), ('ai', '你叫小明。今天有什么我可以帮助你的吗，小明？')]
[('human', '我叫什么名字？'), ('ai', '你叫小明。今天有什么我可以帮助你的吗，小明？')]
```

### 总结消息

裁剪或删除消息的问题在于，你可能会因为消息队列的裁剪而丢失信息。

因此，一些应用可以从更复杂的方法中受益——使用聊天模型总结消息历史。

```
┌─────────────────────────────────────────────────────────────┐
│                     消息历史                                 │
├─────────────────────────────────────────────────────────────┤
│  [旧消息1] [旧消息2] [旧消息3] ... [最近消息1] [最近消息2]    │
│       ↓                                                      │
│    总结为一条摘要消息                                         │
│       ↓                                                      │
│  [摘要] [最近消息1] [最近消息2]                               │
└─────────────────────────────────────────────────────────────┘
```

使用内置的 `SummarizationMiddleware` 在 Agent 中总结消息历史：

```python
from langchain.agents import create_agent
from langchain.agents.middleware import SummarizationMiddleware
from langgraph.checkpoint.memory import InMemorySaver
from langchain_core.runnables import RunnableConfig

checkpointer = InMemorySaver()

agent = create_agent(
    model="gpt-4o",
    tools=[],
    middleware=[
        SummarizationMiddleware(
            model="gpt-4o-mini",      # 用于总结的模型（可以用更便宜的）
            trigger=("tokens", 4000), # 当 token 数超过 4000 时触发总结
            keep=("messages", 20)     # 保留最近 20 条消息
        )
    ],
    checkpointer=checkpointer,
)

config: RunnableConfig = {"configurable": {"thread_id": "1"}}

agent.invoke({"messages": "你好，我叫小明"}, config)
agent.invoke({"messages": "写一首关于猫的短诗"}, config)
agent.invoke({"messages": "现在写一首关于狗的"}, config)
final_response = agent.invoke({"messages": "我叫什么名字？"}, config)

final_response["messages"][-1].pretty_print()
"""
================================== Ai Message ==================================
你叫小明！
"""
```

`SummarizationMiddleware` 参数：

| 参数 | 说明 |
|------|------|
| `model` | 用于生成摘要的模型 |
| `trigger` | 触发总结的条件，如 `("tokens", 4000)` |
| `keep` | 保留的最近消息数量，如 `("messages", 20)` |

## 访问记忆

你可以通过多种方式访问和修改 Agent 的短期记忆（状态）。

### 在工具中访问

#### 读取短期记忆

使用 `runtime` 参数（类型为 `ToolRuntime`）在工具中访问短期记忆（状态）。

`runtime` 参数对工具签名是隐藏的（模型看不到它），但工具可以通过它访问状态：

```python
from langchain.agents import create_agent, AgentState
from langchain.tools import tool, ToolRuntime

class CustomState(AgentState):
    user_id: str

@tool
def get_user_info(runtime: ToolRuntime) -> str:
    """查找用户信息。"""
    user_id = runtime.state["user_id"]
    return "用户是张三" if user_id == "user_123" else "未知用户"

agent = create_agent(
    model="gpt-4o-mini",
    tools=[get_user_info],
    state_schema=CustomState,
)

result = agent.invoke({
    "messages": "查找用户信息",
    "user_id": "user_123"
})

print(result["messages"][-1].content)
# > 用户是张三。
```

#### 从工具写入短期记忆

要在执行过程中修改 Agent 的短期记忆（状态），可以直接从工具返回状态更新。

这对于持久化中间结果或使信息可供后续工具或提示访问很有用：

```python
from langchain.tools import tool, ToolRuntime
from langchain_core.runnables import RunnableConfig
from langchain.messages import ToolMessage
from langchain.agents import create_agent, AgentState
from langgraph.types import Command
from pydantic import BaseModel

class CustomState(AgentState):
    user_name: str

class CustomContext(BaseModel):
    user_id: str

@tool
def update_user_info(runtime: ToolRuntime[CustomContext, CustomState]) -> Command:
    """查找并更新用户信息。"""
    user_id = runtime.context.user_id
    name = "张三" if user_id == "user_123" else "未知用户"
    
    return Command(
        update={
            "user_name": name,
            # 更新消息历史
            "messages": [
                ToolMessage(
                    "成功查找用户信息",
                    tool_call_id=runtime.tool_call_id
                )
            ]
        }
    )

@tool
def greet(runtime: ToolRuntime[CustomContext, CustomState]) -> str | Command:
    """找到用户信息后用于问候用户。"""
    user_name = runtime.state.get("user_name", None)
    
    if user_name is None:
        return Command(
            update={
                "messages": [
                    ToolMessage(
                        "请先调用 'update_user_info' 工具获取用户名称。",
                        tool_call_id=runtime.tool_call_id
                    )
                ]
            }
        )
    
    return f"你好 {user_name}！"

agent = create_agent(
    model="gpt-4o-mini",
    tools=[update_user_info, greet],
    state_schema=CustomState,
    context_schema=CustomContext,
)

agent.invoke(
    {"messages": [{"role": "user", "content": "问候用户"}]},
    context=CustomContext(user_id="user_123"),
)
```

### 在提示中访问

在中间件中访问短期记忆（状态），根据对话历史或自定义状态字段创建动态提示：

```python
from langchain.agents import create_agent
from typing import TypedDict
from langchain.agents.middleware import dynamic_prompt, ModelRequest

class CustomContext(TypedDict):
    user_name: str

def get_weather(city: str) -> str:
    """获取城市的天气。"""
    return f"{city}的天气总是阳光明媚！"

@dynamic_prompt
def dynamic_system_prompt(request: ModelRequest) -> str:
    user_name = request.runtime.context["user_name"]
    system_prompt = f"你是一个有帮助的助手。称呼用户为 {user_name}。"
    return system_prompt

agent = create_agent(
    model="gpt-4o-mini",
    tools=[get_weather],
    middleware=[dynamic_system_prompt],
    context_schema=CustomContext,
)

result = agent.invoke(
    {"messages": [{"role": "user", "content": "旧金山的天气怎么样？"}]},
    context=CustomContext(user_name="张三"),
)

for msg in result["messages"]:
    msg.pretty_print()
```

输出：
```
================================ Human Message =================================
旧金山的天气怎么样？
================================== Ai Message ==================================
Tool Calls:
  get_weather (call_WFQlOGn4b2yoJrv7cih342FG)
  Call ID: call_WFQlOGn4b2yoJrv7cih342FG
    Args:
      city: San Francisco
================================= Tool Message =================================
Name: get_weather
旧金山的天气总是阳光明媚！
================================== Ai Message ==================================
张三，旧金山的天气总是阳光明媚！
```

### 在 before_model 中访问

在 `@before_model` 中间件中访问短期记忆（状态），在模型调用前处理消息：

```mermaid
graph TD
    S(["__start__"])
    PRE(before_model)
    MODEL(model)
    TOOLS(tools)
    END(["__end__"])
    
    S --> PRE
    PRE --> MODEL
    MODEL -.-> TOOLS
    MODEL -.-> END
    TOOLS --> PRE
```

```python
from langchain.messages import RemoveMessage
from langgraph.graph.message import REMOVE_ALL_MESSAGES
from langgraph.checkpoint.memory import InMemorySaver
from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import before_model
from langchain_core.runnables import RunnableConfig
from langgraph.runtime import Runtime
from typing import Any

@before_model
def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
    """只保留最近几条消息以适应上下文窗口。"""
    messages = state["messages"]
    
    if len(messages) <= 3:
        return None  # 不需要修改
    
    first_msg = messages[0]
    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]
    new_messages = [first_msg] + recent_messages
    
    return {
        "messages": [
            RemoveMessage(id=REMOVE_ALL_MESSAGES),
            *new_messages
        ]
    }

agent = create_agent(
    "gpt-4o-mini",
    tools=[],
    middleware=[trim_messages],
    checkpointer=InMemorySaver()
)

config: RunnableConfig = {"configurable": {"thread_id": "1"}}

agent.invoke({"messages": "你好，我叫小明"}, config)
agent.invoke({"messages": "写一首关于猫的短诗"}, config)
agent.invoke({"messages": "现在写一首关于狗的"}, config)
final_response = agent.invoke({"messages": "我叫什么名字？"}, config)

final_response["messages"][-1].pretty_print()
"""
================================== Ai Message ==================================
你叫小明。你之前告诉我的。
如果你想让我用昵称或其他名字称呼你，随时告诉我。
"""
```

### 在 after_model 中访问

在 `@after_model` 中间件中访问短期记忆（状态），在模型调用后处理消息：

```mermaid
graph TD
    S(["__start__"])
    MODEL(model)
    POST(after_model)
    TOOLS(tools)
    END(["__end__"])
    
    S --> MODEL
    MODEL --> POST
    POST -.-> END
    POST -.-> TOOLS
    TOOLS --> MODEL
```

```python
from langchain.messages import RemoveMessage
from langgraph.checkpoint.memory import InMemorySaver
from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import after_model
from langgraph.runtime import Runtime

@after_model
def validate_response(state: AgentState, runtime: Runtime) -> dict | None:
    """移除包含敏感词的消息。"""
    STOP_WORDS = ["password", "secret"]
    
    last_message = state["messages"][-1]
    if any(word in last_message.content for word in STOP_WORDS):
        return {"messages": [RemoveMessage(id=last_message.id)]}
    
    return None

agent = create_agent(
    model="gpt-4o-mini",
    tools=[],
    middleware=[validate_response],
    checkpointer=InMemorySaver(),
)
```

## 总结

| 概念 | 说明 |
|------|------|
| `checkpointer` | 持久化状态，启用短期记忆 |
| `thread_id` | 标识不同对话会话，实现记忆隔离 |
| `AgentState` | 默认状态，包含 `messages` |
| 自定义状态 | 扩展 `AgentState` 添加额外字段 |
| 裁剪消息 | 移除旧消息以适应上下文窗口 |
| 删除消息 | 永久删除特定消息 |
| 总结消息 | 用摘要替换旧消息 |
| `@before_model` | 模型调用前处理状态 |
| `@after_model` | 模型调用后处理状态 |
| `ToolRuntime` | 在工具中访问状态和上下文 |
