# æµå¼è¾“å‡ºè¯¦è§£

æµå¼è¾“å‡ºï¼ˆStreamingï¼‰å¯¹äºæå‡åŸºäº LLM æ„å»ºçš„åº”ç”¨çš„å“åº”æ€§è‡³å…³é‡è¦ã€‚é€šè¿‡åœ¨å®Œæ•´å“åº”å‡†å¤‡å¥½ä¹‹å‰é€æ­¥æ˜¾ç¤ºè¾“å‡ºï¼Œæµå¼è¾“å‡ºæ˜¾è‘—æ”¹å–„äº†ç”¨æˆ·ä½“éªŒï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç† LLM å»¶è¿Ÿæ—¶ã€‚

## æ¦‚è¿°

LangChain çš„æµå¼ç³»ç»Ÿè®©ä½ èƒ½å¤Ÿå°† Agent è¿è¡Œçš„å®æ—¶åé¦ˆå±•ç¤ºç»™åº”ç”¨ã€‚

**æµå¼è¾“å‡ºèƒ½åšä»€ä¹ˆï¼š**

| åŠŸèƒ½ | è¯´æ˜ |
|------|------|
| æµå¼ Agent è¿›åº¦ | æ¯ä¸ª Agent æ­¥éª¤åè·å–çŠ¶æ€æ›´æ–° |
| æµå¼ LLM Token | é€ token æµå¼è¾“å‡ºæ¨¡å‹ç”Ÿæˆçš„å†…å®¹ |
| æµå¼è‡ªå®šä¹‰æ›´æ–° | å‘é€ç”¨æˆ·å®šä¹‰çš„ä¿¡å·ï¼ˆå¦‚ "å·²è·å– 10/100 æ¡è®°å½•"ï¼‰ |
| å¤šæ¨¡å¼æµå¼è¾“å‡º | åŒæ—¶ä½¿ç”¨å¤šç§æµå¼æ¨¡å¼ |

## æ”¯æŒçš„æµå¼æ¨¡å¼

å°†ä»¥ä¸‹æ¨¡å¼ä½œä¸ºåˆ—è¡¨ä¼ é€’ç»™ `stream` æˆ– `astream` æ–¹æ³•ï¼š

| æ¨¡å¼ | è¯´æ˜ |
|------|------|
| `updates` | æ¯ä¸ª Agent æ­¥éª¤åæµå¼è¾“å‡ºçŠ¶æ€æ›´æ–°ã€‚å¦‚æœåŒä¸€æ­¥éª¤ä¸­æœ‰å¤šä¸ªæ›´æ–°ï¼Œå®ƒä»¬ä¼šåˆ†åˆ«æµå¼è¾“å‡º |
| `messages` | ä»ä»»ä½•è°ƒç”¨ LLM çš„å›¾èŠ‚ç‚¹æµå¼è¾“å‡º `(token, metadata)` å…ƒç»„ |
| `custom` | ä½¿ç”¨ stream writer ä»å›¾èŠ‚ç‚¹å†…éƒ¨æµå¼è¾“å‡ºè‡ªå®šä¹‰æ•°æ® |

## Agent è¿›åº¦

ä½¿ç”¨ `stream_mode="updates"` æµå¼è¾“å‡º Agent è¿›åº¦ã€‚è¿™ä¼šåœ¨æ¯ä¸ª Agent æ­¥éª¤åå‘å‡ºä¸€ä¸ªäº‹ä»¶ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœ Agent è°ƒç”¨ä¸€æ¬¡å·¥å…·ï¼Œä½ ä¼šçœ‹åˆ°ä»¥ä¸‹æ›´æ–°ï¼š

1. **LLM èŠ‚ç‚¹**ï¼šå¸¦æœ‰å·¥å…·è°ƒç”¨è¯·æ±‚çš„ `AIMessage`
2. **Tool èŠ‚ç‚¹**ï¼šå¸¦æœ‰æ‰§è¡Œç»“æœçš„ `ToolMessage`
3. **LLM èŠ‚ç‚¹**ï¼šæœ€ç»ˆ AI å“åº”

```python
from langchain.agents import create_agent

def get_weather(city: str) -> str:
    """Get weather for a given city."""
    return f"It's always sunny in {city}!"

agent = create_agent(
    model="gpt-4o",
    tools=[get_weather],
)

for chunk in agent.stream(
    {"messages": [{"role": "user", "content": "æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}]},
    stream_mode="updates",
):
    for step, data in chunk.items():
        print(f"æ­¥éª¤: {step}")
        print(f"å†…å®¹: {data['messages'][-1].content_blocks}")
```

è¾“å‡ºï¼š
```
æ­¥éª¤: model
å†…å®¹: [{'type': 'tool_call', 'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'call_xxx'}]
æ­¥éª¤: tools
å†…å®¹: [{'type': 'text', 'text': "It's always sunny in San Francisco!"}]
æ­¥éª¤: model
å†…å®¹: [{'type': 'text', 'text': 'æ—§é‡‘å±±çš„å¤©æ°”æ€»æ˜¯é˜³å…‰æ˜åªšï¼'}]
```

## LLM Token

ä½¿ç”¨ `stream_mode="messages"` é€ token æµå¼è¾“å‡º LLM ç”Ÿæˆçš„å†…å®¹ï¼š

```python
from langchain.agents import create_agent

def get_weather(city: str) -> str:
    """Get weather for a given city."""
    return f"It's always sunny in {city}!"

agent = create_agent(
    model="gpt-4o",
    tools=[get_weather],
)

for token, metadata in agent.stream(
    {"messages": [{"role": "user", "content": "æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}]},
    stream_mode="messages",
):
    print(f"èŠ‚ç‚¹: {metadata['langgraph_node']}")
    print(f"å†…å®¹: {token.content_blocks}")
```

è¾“å‡ºï¼ˆéƒ¨åˆ†ï¼‰ï¼š
```
èŠ‚ç‚¹: model
å†…å®¹: [{'type': 'tool_call_chunk', 'id': 'call_xxx', 'name': 'get_weather', 'args': '', 'index': 0}]
èŠ‚ç‚¹: model
å†…å®¹: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '{"', 'index': 0}]
èŠ‚ç‚¹: model
å†…å®¹: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': 'city', 'index': 0}]
...
èŠ‚ç‚¹: tools
å†…å®¹: [{'type': 'text', 'text': "It's always sunny in San Francisco!"}]
èŠ‚ç‚¹: model
å†…å®¹: [{'type': 'text', 'text': 'æ—§é‡‘å±±'}]
èŠ‚ç‚¹: model
å†…å®¹: [{'type': 'text', 'text': 'çš„å¤©æ°”'}]
èŠ‚ç‚¹: model
å†…å®¹: [{'type': 'text', 'text': 'æ€»æ˜¯'}]
èŠ‚ç‚¹: model
å†…å®¹: [{'type': 'text', 'text': 'é˜³å…‰æ˜åªš'}]
èŠ‚ç‚¹: model
å†…å®¹: [{'type': 'text', 'text': 'ï¼'}]
```

## è‡ªå®šä¹‰æ›´æ–°

ä½¿ç”¨ `get_stream_writer` åœ¨å·¥å…·æ‰§è¡Œæ—¶æµå¼è¾“å‡ºè‡ªå®šä¹‰æ›´æ–°ï¼š

```python
from langchain.agents import create_agent
from langgraph.config import get_stream_writer

def get_weather(city: str) -> str:
    """Get weather for a given city."""
    writer = get_stream_writer()  # è·å– stream writer
    
    # æµå¼è¾“å‡ºä»»æ„æ•°æ®
    writer(f"æ­£åœ¨æŸ¥æ‰¾åŸå¸‚æ•°æ®: {city}")
    writer(f"å·²è·å– {city} çš„æ•°æ®")
    
    return f"It's always sunny in {city}!"

agent = create_agent(
    model="gpt-4o",
    tools=[get_weather],
)

for chunk in agent.stream(
    {"messages": [{"role": "user", "content": "æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}]},
    stream_mode="custom"  # ä½¿ç”¨ custom æ¨¡å¼
):
    print(chunk)
```

è¾“å‡ºï¼š
```
æ­£åœ¨æŸ¥æ‰¾åŸå¸‚æ•°æ®: San Francisco
å·²è·å– San Francisco çš„æ•°æ®
```

> âš ï¸ å¦‚æœåœ¨å·¥å…·ä¸­ä½¿ç”¨ `get_stream_writer`ï¼Œè¯¥å·¥å…·åªèƒ½åœ¨ LangGraph æ‰§è¡Œä¸Šä¸‹æ–‡ä¸­è°ƒç”¨ã€‚

## å¤šæ¨¡å¼æµå¼è¾“å‡º

å¯ä»¥åŒæ—¶æŒ‡å®šå¤šç§æµå¼æ¨¡å¼ï¼š`stream_mode=["updates", "custom"]`

è¾“å‡ºå°†æ˜¯ `(mode, chunk)` å…ƒç»„ï¼Œå…¶ä¸­ `mode` æ˜¯æµå¼æ¨¡å¼åç§°ï¼Œ`chunk` æ˜¯è¯¥æ¨¡å¼æµå¼è¾“å‡ºçš„æ•°æ®ï¼š

```python
from langchain.agents import create_agent
from langgraph.config import get_stream_writer

def get_weather(city: str) -> str:
    """Get weather for a given city."""
    writer = get_stream_writer()
    writer(f"æ­£åœ¨æŸ¥æ‰¾åŸå¸‚æ•°æ®: {city}")
    writer(f"å·²è·å– {city} çš„æ•°æ®")
    return f"It's always sunny in {city}!"

agent = create_agent(
    model="gpt-4o",
    tools=[get_weather],
)

for stream_mode, chunk in agent.stream(
    {"messages": [{"role": "user", "content": "æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}]},
    stream_mode=["updates", "custom"]  # å¤šç§æ¨¡å¼
):
    print(f"æ¨¡å¼: {stream_mode}")
    print(f"å†…å®¹: {chunk}")
    print()
```

è¾“å‡ºï¼š
```
æ¨¡å¼: updates
å†…å®¹: {'model': {'messages': [AIMessage(content='', tool_calls=[...])]}}

æ¨¡å¼: custom
å†…å®¹: æ­£åœ¨æŸ¥æ‰¾åŸå¸‚æ•°æ®: San Francisco

æ¨¡å¼: custom
å†…å®¹: å·²è·å– San Francisco çš„æ•°æ®

æ¨¡å¼: updates
å†…å®¹: {'tools': {'messages': [ToolMessage(content="It's always sunny in San Francisco!")]}}

æ¨¡å¼: updates
å†…å®¹: {'model': {'messages': [AIMessage(content='æ—§é‡‘å±±çš„å¤©æ°”æ€»æ˜¯é˜³å…‰æ˜åªšï¼')]}}
```

## å¸¸è§æ¨¡å¼

### æµå¼å·¥å…·è°ƒç”¨

ä½ å¯èƒ½æƒ³åŒæ—¶æµå¼è¾“å‡ºï¼š
1. å·¥å…·è°ƒç”¨ç”Ÿæˆæ—¶çš„éƒ¨åˆ† JSON
2. æ‰§è¡Œçš„å®Œæ•´ã€å·²è§£æçš„å·¥å…·è°ƒç”¨

```python
from typing import Any
from langchain.agents import create_agent
from langchain.messages import AIMessage, AIMessageChunk, AnyMessage, ToolMessage

def get_weather(city: str) -> str:
    """Get weather for a given city."""
    return f"It's always sunny in {city}!"

agent = create_agent("gpt-4o", tools=[get_weather])

def _render_message_chunk(token: AIMessageChunk) -> None:
    if token.text:
        print(token.text, end="|")
    if token.tool_call_chunks:
        print(token.tool_call_chunks)

def _render_completed_message(message: AnyMessage) -> None:
    if isinstance(message, AIMessage) and message.tool_calls:
        print(f"å·¥å…·è°ƒç”¨: {message.tool_calls}")
    if isinstance(message, ToolMessage):
        print(f"å·¥å…·å“åº”: {message.content_blocks}")

input_message = {"role": "user", "content": "æ³¢å£«é¡¿çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}

for stream_mode, data in agent.stream(
    {"messages": [input_message]},
    stream_mode=["messages", "updates"],  # åŒæ—¶ä½¿ç”¨ä¸¤ç§æ¨¡å¼
):
    if stream_mode == "messages":
        token, metadata = data
        if isinstance(token, AIMessageChunk):
            _render_message_chunk(token)  # æµå¼è¾“å‡º token
    
    if stream_mode == "updates":
        for source, update in data.items():
            if source in ("model", "tools"):
                _render_completed_message(update["messages"][-1])  # å®Œæ•´æ¶ˆæ¯
```

è¾“å‡ºï¼š
```
[{'name': 'get_weather', 'args': '', 'id': 'call_xxx', 'index': 0, 'type': 'tool_call_chunk'}]
[{'name': None, 'args': '{"', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]
[{'name': None, 'args': 'city', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]
[{'name': None, 'args': '":"', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]
[{'name': None, 'args': 'Boston', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]
[{'name': None, 'args': '"}', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]
å·¥å…·è°ƒç”¨: [{'name': 'get_weather', 'args': {'city': 'Boston'}, 'id': 'call_xxx', 'type': 'tool_call'}]
å·¥å…·å“åº”: [{'type': 'text', 'text': "It's always sunny in Boston!"}]
The| weather| in| Boston| is| **|sun|ny|**|.|
```

### ç´¯ç§¯ chunks æ„å»ºå®Œæ•´æ¶ˆæ¯

å¦‚æœéœ€è¦åœ¨æµå¼å¾ªç¯ä¸­èšåˆæ¶ˆæ¯ chunksï¼š

```python
input_message = {"role": "user", "content": "æ³¢å£«é¡¿çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}

full_message = None

for stream_mode, data in agent.stream(
    {"messages": [input_message]},
    stream_mode=["messages", "updates"],
):
    if stream_mode == "messages":
        token, metadata = data
        if isinstance(token, AIMessageChunk):
            _render_message_chunk(token)
            # ç´¯ç§¯ chunks
            full_message = token if full_message is None else full_message + token
            
            if token.chunk_position == "last":  # æœ€åä¸€ä¸ª chunk
                if full_message.tool_calls:
                    print(f"å·¥å…·è°ƒç”¨: {full_message.tool_calls}")
                full_message = None  # é‡ç½®
    
    if stream_mode == "updates":
        for source, update in data.items():
            if source == "tools":
                _render_completed_message(update["messages"][-1])
```

### ä»å­ Agent æµå¼è¾“å‡º

å½“æœ‰å¤šä¸ª LLM æ—¶ï¼Œé€šå¸¸éœ€è¦åŒºåˆ†æ¶ˆæ¯çš„æ¥æºã€‚

#### å­ Agent çš„è°ƒç”¨æ–¹å¼

åœ¨ LangChain ä¸­ï¼Œ**å­ Agent é€šå¸¸è¢«åŒ…è£…æˆå·¥å…·**ä¾›ä¸» Agent è°ƒç”¨ï¼š

```python
# åˆ›å»ºå­ Agent
weather_agent = create_agent(model=weather_model, tools=[get_weather])

# æŠŠå­ Agent åŒ…è£…æˆå·¥å…·
def call_weather_agent(query: str) -> str:
    """Query the weather agent."""
    result = weather_agent.invoke({"messages": [{"role": "user", "content": query}]})
    return result["messages"][-1].text

# ä¸» Agent æŠŠå­ Agent å½“ä½œå·¥å…·ä½¿ç”¨
agent = create_agent(model=supervisor_model, tools=[call_weather_agent])
```

**ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ**

- å­ Agent å¯¹ä¸» Agent æ¥è¯´å°±æ˜¯ä¸€ä¸ª"èƒ½åŠ›"ï¼Œå’Œæ™®é€šå·¥å…·æ²¡åŒºåˆ«
- ä¸» Agent å†³å®šä½•æ—¶è°ƒç”¨ã€ä¼ ä»€ä¹ˆå‚æ•°
- ç¬¦åˆ ReAct æ¨¡å¼ï¼šä¸» Agent æ˜¯"å¤§è„‘"ï¼Œå­ Agent æ˜¯"ä¸“ä¸šå·¥å…·"

**æ‰§è¡Œæµç¨‹ï¼š**

```
ç”¨æˆ·: "æ³¢å£«é¡¿çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
        â†“
ä¸» Agent (supervisor) æ€è€ƒ:
  "è¿™æ˜¯å¤©æ°”é—®é¢˜ï¼Œæˆ‘æœ‰ä¸ª call_weather_agent å·¥å…·"
        â†“
è°ƒç”¨å·¥å…·: call_weather_agent("æ³¢å£«é¡¿å¤©æ°”")
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å­ Agent (weather_sub_agent) æ‰§è¡Œ   â”‚
â”‚   â†“                                 â”‚
â”‚ è°ƒç”¨ get_weather("Boston")          â”‚
â”‚   â†“                                 â”‚
â”‚ è¿”å›: "It's always sunny in Boston!"â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
ä¸» Agent æ”¶åˆ°ç»“æœï¼Œç»„ç»‡æœ€ç»ˆå›ç­”
```

#### åŒºåˆ†å¤šä¸ª LLM çš„æ¥æº

å¯ä»¥ä½¿ç”¨ `tags` åˆå§‹åŒ–æ¨¡å‹ï¼Œè¿™äº›æ ‡ç­¾åœ¨ `"messages"` æ¨¡å¼æµå¼è¾“å‡ºæ—¶å¯ä»¥åœ¨ metadata ä¸­è®¿é—®ï¼š

```python
from langchain.agents import create_agent
from langchain.chat_models import init_chat_model
from langchain.messages import AIMessage, AIMessageChunk

def get_weather(city: str) -> str:
    """Get weather for a given city."""
    return f"It's always sunny in {city}!"

# å­ Agent çš„æ¨¡å‹ï¼Œå¸¦æ ‡ç­¾
weather_model = init_chat_model(
    "gpt-4o",
    tags=["weather_sub_agent"],  # æ ‡ç­¾
)
weather_agent = create_agent(model=weather_model, tools=[get_weather])

def call_weather_agent(query: str) -> str:
    """Query the weather agent."""
    result = weather_agent.invoke({"messages": [{"role": "user", "content": query}]})
    return result["messages"][-1].text

# ä¸» Agent çš„æ¨¡å‹ï¼Œå¸¦æ ‡ç­¾
supervisor_model = init_chat_model(
    "gpt-4o",
    tags=["supervisor"],  # æ ‡ç­¾
)
agent = create_agent(model=supervisor_model, tools=[call_weather_agent])

# æµå¼è¾“å‡ºæ—¶åŒºåˆ†æ¥æº
input_message = {"role": "user", "content": "æ³¢å£«é¡¿çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}
current_agent = None

for _, stream_mode, data in agent.stream(
    {"messages": [input_message]},
    stream_mode=["messages", "updates"],
    subgraphs=True,  # å¯ç”¨å­å›¾æµå¼è¾“å‡º
):
    if stream_mode == "messages":
        token, metadata = data
        if tags := metadata.get("tags", []):
            this_agent = tags[0]
            if this_agent != current_agent:
                print(f"ğŸ¤– {this_agent}: ")
                current_agent = this_agent
        
        if isinstance(token, AIMessage):
            _render_message_chunk(token)
    
    if stream_mode == "updates":
        for source, update in data.items():
            if source in ("model", "tools"):
                _render_completed_message(update["messages"][-1])
```

è¾“å‡ºï¼š
```
ğŸ¤– supervisor: 
[{'name': 'call_weather_agent', 'args': '', 'id': 'call_xxx', ...}]
...
å·¥å…·è°ƒç”¨: [{'name': 'call_weather_agent', 'args': {'query': 'Boston weather'}, ...}]
ğŸ¤– weather_sub_agent: 
[{'name': 'get_weather', 'args': '', 'id': 'call_yyy', ...}]
...
å·¥å…·è°ƒç”¨: [{'name': 'get_weather', 'args': {'city': 'Boston'}, ...}]
å·¥å…·å“åº”: [{'type': 'text', 'text': "It's always sunny in Boston!"}]
Boston| weather|:| **|Sunny|**|
ğŸ¤– supervisor: 
Boston| weather|:| **|Sunny|**|
```

## ç¦ç”¨æµå¼è¾“å‡º

åœ¨æŸäº›åº”ç”¨ä¸­ï¼Œä½ å¯èƒ½éœ€è¦ç¦ç”¨ç‰¹å®šæ¨¡å‹çš„ token æµå¼è¾“å‡ºã€‚è¿™åœ¨ä»¥ä¸‹æƒ…å†µä¸‹å¾ˆæœ‰ç”¨ï¼š

- åœ¨å¤š Agent ç³»ç»Ÿä¸­æ§åˆ¶å“ªäº› Agent æµå¼è¾“å‡º
- æ··åˆä½¿ç”¨æ”¯æŒå’Œä¸æ”¯æŒæµå¼è¾“å‡ºçš„æ¨¡å‹
- éƒ¨ç½²åˆ° LangSmith æ—¶æƒ³é˜»æ­¢æŸäº›æ¨¡å‹è¾“å‡ºè¢«æµå¼ä¼ è¾“åˆ°å®¢æˆ·ç«¯

åˆå§‹åŒ–æ¨¡å‹æ—¶è®¾ç½® `streaming=False`ï¼š

```python
from langchain_openai import ChatOpenAI

model = ChatOpenAI(
    model="gpt-4o",
    streaming=False  # ç¦ç”¨æµå¼è¾“å‡º
)
```

> âš ï¸ å¹¶éæ‰€æœ‰èŠå¤©æ¨¡å‹é›†æˆéƒ½æ”¯æŒ `streaming` å‚æ•°ã€‚å¦‚æœä½ çš„æ¨¡å‹ä¸æ”¯æŒï¼Œå¯ä»¥ä½¿ç”¨ `disable_streaming=True`ï¼Œè¿™ä¸ªå‚æ•°åœ¨æ‰€æœ‰èŠå¤©æ¨¡å‹çš„åŸºç±»ä¸­éƒ½å¯ç”¨ã€‚

## ä¸‰ç§æ¨¡å¼å¯¹æ¯”

| æ¨¡å¼ | ç”¨é€” | è¾“å‡ºå†…å®¹ |
|------|------|----------|
| `updates` | è·Ÿè¸ª Agent æ‰§è¡Œè¿›åº¦ | æ¯ä¸ªæ­¥éª¤çš„å®Œæ•´çŠ¶æ€æ›´æ–° |
| `messages` | å®æ—¶æ˜¾ç¤º LLM ç”Ÿæˆå†…å®¹ | é€ token è¾“å‡º + metadata |
| `custom` | è‡ªå®šä¹‰è¿›åº¦åé¦ˆ | ä»»æ„ç”¨æˆ·å®šä¹‰çš„æ•°æ® |

## æ€»ç»“

| æ¦‚å¿µ | è¯´æ˜ |
|------|------|
| `stream_mode="updates"` | æµå¼è¾“å‡º Agent æ­¥éª¤è¿›åº¦ |
| `stream_mode="messages"` | æµå¼è¾“å‡º LLM token |
| `stream_mode="custom"` | æµå¼è¾“å‡ºè‡ªå®šä¹‰æ•°æ® |
| `get_stream_writer()` | åœ¨å·¥å…·ä¸­è·å– stream writer |
| `subgraphs=True` | å¯ç”¨å­å›¾æµå¼è¾“å‡º |
| `tags` | æ ‡è®°æ¨¡å‹æ¥æºï¼ŒåŒºåˆ†å¤šä¸ª LLM |
| `streaming=False` | ç¦ç”¨ç‰¹å®šæ¨¡å‹çš„æµå¼è¾“å‡º |
