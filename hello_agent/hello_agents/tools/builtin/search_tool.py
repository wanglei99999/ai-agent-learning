"""æœç´¢å·¥å…· - HelloAgents åŽŸç”Ÿæœç´¢å®žçŽ°ã€‚"""

from __future__ import annotations

import logging
import os
from typing import Any, Dict, Iterable, List

import requests

from ..base import Tool, ToolParameter

try:  # å¯é€‰ä¾èµ–ï¼Œç¼ºå¤±æ—¶é™çº§èƒ½åŠ›
    from markdownify import markdownify
except Exception:  # pragma: no cover - å¯é€‰ä¾èµ–
    markdownify = None  # type: ignore

try:
    from ddgs import DDGS  # type: ignore
except Exception:  # pragma: no cover - å¯é€‰ä¾èµ–
    DDGS = None  # type: ignore

try:
    from tavily import TavilyClient  # type: ignore
except Exception:  # pragma: no cover - å¯é€‰ä¾èµ–
    TavilyClient = None  # type: ignore

try:
    from serpapi import GoogleSearch  # type: ignore
except Exception:  # pragma: no cover - å¯é€‰ä¾èµ–
    GoogleSearch = None  # type: ignore

logger = logging.getLogger(__name__)

CHARS_PER_TOKEN = 4
DEFAULT_MAX_RESULTS = 5
SUPPORTED_RETURN_MODES = {"text", "structured", "json", "dict"}
SUPPORTED_BACKENDS = {
    "hybrid",
    "advanced",
    "tavily",
    "serpapi",
    "duckduckgo",
    "searxng",
    "perplexity",
}


def _limit_text(text: str, token_limit: int) -> str:
    char_limit = token_limit * CHARS_PER_TOKEN
    if len(text) <= char_limit:
        return text
    return text[:char_limit] + "... [truncated]"


def _fetch_raw_content(url: str) -> str | None:
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
    except Exception as exc:  # pragma: no cover - ç½‘ç»œçŽ¯å¢ƒä¸ç¨³å®š
        logger.debug("Failed to fetch raw content for %s: %s", url, exc)
        return None

    if markdownify is not None:
        try:
            return markdownify(response.text)  # type: ignore[arg-type]
        except Exception as exc:  # pragma: no cover - å¯é€‰ä¾èµ–å¤±è´¥
            logger.debug("markdownify failed for %s: %s", url, exc)
    return response.text


def _normalized_result(
    *,
    title: str,
    url: str,
    content: str,
    raw_content: str | None,
) -> Dict[str, str]:
    payload: Dict[str, str] = {
        "title": title or url,
        "url": url,
        "content": content or "",
    }
    if raw_content is not None:
        payload["raw_content"] = raw_content
    return payload


def _structured_payload(
    results: Iterable[Dict[str, Any]],
    *,
    backend: str,
    answer: str | None = None,
    notices: Iterable[str] | None = None,
) -> Dict[str, Any]:
    return {
        "results": list(results),
        "backend": backend,
        "answer": answer,
        "notices": list(notices or []),
    }


class SearchTool(Tool):
    """æ”¯æŒå¤šåŽç«¯ã€å¯è¿”å›žç»“æž„åŒ–ç»“æžœçš„æœç´¢å·¥å…·ã€‚"""

    def __init__(
        self,
        backend: str = "hybrid",
        tavily_key: str | None = None,
        serpapi_key: str | None = None,
        perplexity_key: str | None = None,
    ) -> None:
        super().__init__(
            name="search",
            description=(
                "æ™ºèƒ½ç½‘é¡µæœç´¢å¼•æ“Žï¼Œæ”¯æŒ Tavilyã€SerpApiã€DuckDuckGoã€SearXNGã€"
                "Perplexity ç­‰åŽç«¯ï¼Œå¯è¿”å›žç»“æž„åŒ–æˆ–æ–‡æœ¬åŒ–çš„æœç´¢ç»“æžœã€‚"
            ),
        )
        self.backend = (backend or "hybrid").lower()
        self.tavily_key = tavily_key or os.getenv("TAVILY_API_KEY")
        self.serpapi_key = serpapi_key or os.getenv("SERPAPI_API_KEY")
        self.perplexity_key = perplexity_key or os.getenv("PERPLEXITY_API_KEY")

        self.available_backends: list[str] = []
        self.tavily_client = None
        self._setup_backends()

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------
    def run(self, parameters: Dict[str, Any]) -> str | Dict[str, Any]:  # type: ignore[override]
        query = (parameters.get("input") or parameters.get("query") or "").strip()
        if not query:
            return "é”™è¯¯ï¼šæœç´¢æŸ¥è¯¢ä¸èƒ½ä¸ºç©º"

        backend = str(parameters.get("backend", self.backend) or "hybrid").lower()
        backend = backend if backend in SUPPORTED_BACKENDS else "hybrid"

        mode = str(
            parameters.get("mode")
            or parameters.get("return_mode")
            or "text"
        ).lower()
        if mode not in SUPPORTED_RETURN_MODES:
            mode = "text"

        fetch_full_page = bool(parameters.get("fetch_full_page", False))
        max_results = int(parameters.get("max_results", DEFAULT_MAX_RESULTS))
        max_tokens = int(parameters.get("max_tokens_per_source", 2000))
        loop_count = int(parameters.get("loop_count", 0))

        payload = self._structured_search(
            query=query,
            backend=backend,
            fetch_full_page=fetch_full_page,
            max_results=max_results,
            max_tokens=max_tokens,
            loop_count=loop_count,
        )

        if mode in {"structured", "json", "dict"}:
            return payload

        return self._format_text_response(query=query, payload=payload)

    def get_parameters(self) -> List[ToolParameter]:
        return [
            ToolParameter(
                name="input",
                type="string",
                description="æœç´¢æŸ¥è¯¢å…³é”®è¯",
                required=True,
            ),
        ]

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------
    def _setup_backends(self) -> None:
        if self.tavily_key and TavilyClient is not None:
            try:
                self.tavily_client = TavilyClient(api_key=self.tavily_key)
                self.available_backends.append("tavily")
                print("âœ… Tavily æœç´¢å¼•æ“Žå·²åˆå§‹åŒ–")
            except Exception as exc:  # pragma: no cover - ç¬¬ä¸‰æ–¹åº“åˆå§‹åŒ–å¤±è´¥
                print(f"âš ï¸ Tavily åˆå§‹åŒ–å¤±è´¥: {exc}")
        elif self.tavily_key:
            print("âš ï¸ æœªå®‰è£… tavily-pythonï¼Œæ— æ³•ä½¿ç”¨ Tavily æœç´¢")
        else:
            print("âš ï¸ TAVILY_API_KEY æœªè®¾ç½®")

        if self.serpapi_key:
            if GoogleSearch is not None:
                self.available_backends.append("serpapi")
                print("âœ… SerpApi æœç´¢å¼•æ“Žå·²åˆå§‹åŒ–")
            else:
                print("âš ï¸ æœªå®‰è£… google-search-resultsï¼Œæ— æ³•ä½¿ç”¨ SerpApi æœç´¢")
        else:
            print("âš ï¸ SERPAPI_API_KEY æœªè®¾ç½®")

        if self.backend not in SUPPORTED_BACKENDS:
            print("âš ï¸ ä¸æ”¯æŒçš„æœç´¢åŽç«¯ï¼Œå°†ä½¿ç”¨ hybrid æ¨¡å¼")
            self.backend = "hybrid"
        elif self.backend == "tavily" and "tavily" not in self.available_backends:
            print("âš ï¸ Tavily ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ hybrid æ¨¡å¼")
            self.backend = "hybrid"
        elif self.backend == "serpapi" and "serpapi" not in self.available_backends:
            print("âš ï¸ SerpApi ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ hybrid æ¨¡å¼")
            self.backend = "hybrid"

        if self.backend == "hybrid":
            if self.available_backends:
                print(
                    "ðŸ”§ æ··åˆæœç´¢æ¨¡å¼å·²å¯ç”¨ï¼Œå¯ç”¨åŽç«¯: "
                    + ", ".join(self.available_backends)
                )
            else:
                print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„ Tavily/SerpApi æœç´¢æºï¼Œå°†å›žé€€åˆ°é€šç”¨æ¨¡å¼")

    def _structured_search(
        self,
        *,
        query: str,
        backend: str,
        fetch_full_page: bool,
        max_results: int,
        max_tokens: int,
        loop_count: int,
    ) -> Dict[str, Any]:
        # ç»Ÿä¸€å°† hybrid è§†ä½œ advancedï¼Œä»¥ä¿æŒå‘åŽå…¼å®¹çš„ä¼˜å…ˆçº§é€»è¾‘
        target_backend = "advanced" if backend == "hybrid" else backend

        if target_backend == "tavily":
            return self._search_tavily(
                query=query,
                fetch_full_page=fetch_full_page,
                max_results=max_results,
                max_tokens=max_tokens,
            )
        if target_backend == "serpapi":
            return self._search_serpapi(
                query=query,
                fetch_full_page=fetch_full_page,
                max_results=max_results,
                max_tokens=max_tokens,
            )
        if target_backend == "duckduckgo":
            return self._search_duckduckgo(
                query=query,
                fetch_full_page=fetch_full_page,
                max_results=max_results,
                max_tokens=max_tokens,
            )
        if target_backend == "searxng":
            return self._search_searxng(
                query=query,
                fetch_full_page=fetch_full_page,
                max_results=max_results,
                max_tokens=max_tokens,
            )
        if target_backend == "perplexity":
            return self._search_perplexity(
                query=query,
                fetch_full_page=fetch_full_page,
                max_results=max_results,
                max_tokens=max_tokens,
                loop_count=loop_count,
            )
        if target_backend == "advanced":
            return self._search_advanced(
                query=query,
                fetch_full_page=fetch_full_page,
                max_results=max_results,
                max_tokens=max_tokens,
                loop_count=loop_count,
            )

        raise ValueError(f"Unsupported search backend: {backend}")

    def _search_tavily(
        self,
        *,
        query: str,
        fetch_full_page: bool,
        max_results: int,
        max_tokens: int,
    ) -> Dict[str, Any]:
        if not self.tavily_client:
            message = "TAVILY_API_KEY æœªé…ç½®æˆ– tavily æœªå®‰è£…"
            raise RuntimeError(message)

        response = self.tavily_client.search(  # type: ignore[call-arg]
            query=query,
            max_results=max_results,
            include_raw_content=fetch_full_page,
        )

        results = []
        for item in response.get("results", [])[:max_results]:
            raw = item.get("raw_content") if fetch_full_page else item.get("content")
            if raw and fetch_full_page:
                raw = _limit_text(raw, max_tokens)
            results.append(
                _normalized_result(
                    title=item.get("title") or item.get("url", ""),
                    url=item.get("url", ""),
                    content=item.get("content") or "",
                    raw_content=raw,
                )
            )

        return _structured_payload(
            results,
            backend="tavily",
            answer=response.get("answer"),
        )

    def _search_serpapi(
        self,
        *,
        query: str,
        fetch_full_page: bool,
        max_results: int,
        max_tokens: int,
    ) -> Dict[str, Any]:
        if not self.serpapi_key:
            raise RuntimeError("SERPAPI_API_KEY æœªé…ç½®ï¼Œæ— æ³•ä½¿ç”¨ SerpApi æœç´¢")
        if GoogleSearch is None:
            raise RuntimeError("æœªå®‰è£… google-search-resultsï¼Œæ— æ³•ä½¿ç”¨ SerpApi")

        params = {
            "engine": "google",
            "q": query,
            "api_key": self.serpapi_key,
            "gl": "cn",
            "hl": "zh-cn",
            "num": max_results,
        }

        response = GoogleSearch(params).get_dict()

        answer_box = response.get("answer_box") or {}
        answer = answer_box.get("answer") or answer_box.get("snippet")

        results = []
        for item in response.get("organic_results", [])[:max_results]:
            raw_content = item.get("snippet")
            if raw_content and fetch_full_page:
                raw_content = _limit_text(raw_content, max_tokens)
            results.append(
                _normalized_result(
                    title=item.get("title") or item.get("link", ""),
                    url=item.get("link", ""),
                    content=item.get("snippet") or "",
                    raw_content=raw_content,
                )
            )

        return _structured_payload(results, backend="serpapi", answer=answer)

    def _search_duckduckgo(
        self,
        *,
        query: str,
        fetch_full_page: bool,
        max_results: int,
        max_tokens: int,
    ) -> Dict[str, Any]:
        if DDGS is None:
            raise RuntimeError("æœªå®‰è£… ddgsï¼Œæ— æ³•ä½¿ç”¨ DuckDuckGo æœç´¢")

        results: List[Dict[str, Any]] = []
        notices: List[str] = []

        try:
            with DDGS(timeout=10) as client:  # type: ignore[call-arg]
                search_results = client.text(query, max_results=max_results, backend="duckduckgo")
        except Exception as exc:  # pragma: no cover - ç½‘ç»œå¼‚å¸¸
            raise RuntimeError(f"DuckDuckGo æœç´¢å¤±è´¥: {exc}")

        for entry in search_results:
            url = entry.get("href") or entry.get("url")
            title = entry.get("title") or url or ""
            content = entry.get("body") or entry.get("content") or ""

            if not url or not title:
                notices.append(f"å¿½ç•¥ä¸å®Œæ•´çš„ DuckDuckGo ç»“æžœ: {entry}")
                continue

            raw_content = content
            if fetch_full_page and url:
                fetched = _fetch_raw_content(url)
                if fetched:
                    raw_content = _limit_text(fetched, max_tokens)

            results.append(
                _normalized_result(
                    title=title,
                    url=url,
                    content=content,
                    raw_content=raw_content,
                )
            )

        return _structured_payload(results, backend="duckduckgo", notices=notices)

    def _search_searxng(
        self,
        *,
        query: str,
        fetch_full_page: bool,
        max_results: int,
        max_tokens: int,
    ) -> Dict[str, Any]:
        host = os.getenv("SEARXNG_URL", "http://localhost:8888").rstrip("/")
        endpoint = f"{host}/search"

        try:
            response = requests.get(
                endpoint,
                params={
                    "q": query,
                    "format": "json",
                    "language": "zh-CN",
                    "safesearch": 1,
                    "categories": "general",
                },
                timeout=10,
            )
            response.raise_for_status()
            payload = response.json()
        except Exception as exc:  # pragma: no cover - ç½‘ç»œå¼‚å¸¸
            raise RuntimeError(f"SearXNG æœç´¢å¤±è´¥: {exc}")

        results = []
        for entry in payload.get("results", [])[:max_results]:
            url = entry.get("url") or entry.get("link")
            title = entry.get("title") or url or ""
            if not url or not title:
                continue
            content = entry.get("content") or entry.get("snippet") or ""
            raw_content = content
            if fetch_full_page and url:
                fetched = _fetch_raw_content(url)
                if fetched:
                    raw_content = _limit_text(fetched, max_tokens)
            results.append(
                _normalized_result(
                    title=title,
                    url=url,
                    content=content,
                    raw_content=raw_content,
                )
            )

        return _structured_payload(results, backend="searxng")

    def _search_perplexity(
        self,
        *,
        query: str,
        fetch_full_page: bool,
        max_results: int,
        max_tokens: int,
        loop_count: int,
    ) -> Dict[str, Any]:
        if not self.perplexity_key:
            raise RuntimeError("PERPLEXITY_API_KEY æœªé…ç½®ï¼Œæ— æ³•ä½¿ç”¨ Perplexity æœç´¢")

        headers = {
            "accept": "application/json",
            "content-type": "application/json",
            "Authorization": f"Bearer {self.perplexity_key}",
        }
        payload = {
            "model": "sonar-pro",
            "messages": [
                {
                    "role": "system",
                    "content": "Search the web and provide factual information with sources.",
                },
                {"role": "user", "content": query},
            ],
        }

        response = requests.post(
            "https://api.perplexity.ai/chat/completions",
            headers=headers,
            json=payload,
            timeout=30,
        )
        response.raise_for_status()
        data = response.json()

        content = data["choices"][0]["message"]["content"]
        citations = data.get("citations", []) or ["https://perplexity.ai"]

        results = []
        for idx, url in enumerate(citations[:max_results], start=1):
            snippet = content if idx == 1 else "See main Perplexity response above."
            raw = _limit_text(content, max_tokens) if fetch_full_page and idx == 1 else None
            results.append(
                _normalized_result(
                    title=f"Perplexity Source {loop_count + 1}-{idx}",
                    url=url,
                    content=snippet,
                    raw_content=raw,
                )
            )

        return _structured_payload(results, backend="perplexity", answer=content)

    def _search_advanced(
        self,
        *,
        query: str,
        fetch_full_page: bool,
        max_results: int,
        max_tokens: int,
        loop_count: int,
    ) -> Dict[str, Any]:
        notices: List[str] = []
        aggregated: List[Dict[str, Any]] = []
        answer: str | None = None
        backend_used = "advanced"

        if self.tavily_client:
            try:
                tavily_payload = self._search_tavily(
                    query=query,
                    fetch_full_page=fetch_full_page,
                    max_results=max_results,
                    max_tokens=max_tokens,
                )
                if tavily_payload["results"]:
                    return tavily_payload
                notices.append("âš ï¸ Tavily æœªè¿”å›žæœ‰æ•ˆç»“æžœï¼Œå°è¯•å…¶ä»–æœç´¢æº")
            except Exception as exc:  # pragma: no cover - ç¬¬ä¸‰æ–¹åº“å¼‚å¸¸
                notices.append(f"âš ï¸ Tavily æœç´¢å¤±è´¥ï¼š{exc}")

        if self.serpapi_key and GoogleSearch is not None:
            try:
                serp_payload = self._search_serpapi(
                    query=query,
                    fetch_full_page=fetch_full_page,
                    max_results=max_results,
                    max_tokens=max_tokens,
                )
                if serp_payload["results"]:
                    serp_payload["notices"] = notices + serp_payload.get("notices", [])
                    return serp_payload
                notices.append("âš ï¸ SerpApi æœªè¿”å›žæœ‰æ•ˆç»“æžœï¼Œå›žé€€åˆ°é€šç”¨æœç´¢")
            except Exception as exc:  # pragma: no cover - ç¬¬ä¸‰æ–¹åº“å¼‚å¸¸
                notices.append(f"âš ï¸ SerpApi æœç´¢å¤±è´¥ï¼š{exc}")

        try:
            ddg_payload = self._search_duckduckgo(
                query=query,
                fetch_full_page=fetch_full_page,
                max_results=max_results,
                max_tokens=max_tokens,
            )
            aggregated.extend(ddg_payload["results"])
            notices.extend(ddg_payload.get("notices", []))
            backend_used = ddg_payload.get("backend", backend_used)
        except Exception as exc:  # pragma: no cover - é€šç”¨å…œåº•
            notices.append(f"âš ï¸ DuckDuckGo æœç´¢å¤±è´¥ï¼š{exc}")

        return _structured_payload(
            aggregated,
            backend=backend_used,
            answer=answer,
            notices=notices,
        )

    def _format_text_response(self, *, query: str, payload: Dict[str, Any]) -> str:
        answer = payload.get("answer")
        notices = payload.get("notices") or []
        results = payload.get("results") or []
        backend = payload.get("backend", self.backend)

        lines = [f"ðŸ” æœç´¢å…³é”®è¯ï¼š{query}", f"ðŸ§­ ä½¿ç”¨æœç´¢æºï¼š{backend}"]
        if answer:
            lines.append(f"ðŸ’¡ ç›´æŽ¥ç­”æ¡ˆï¼š{answer}")

        if results:
            lines.append("")
            lines.append("ðŸ“š å‚è€ƒæ¥æºï¼š")
            for idx, item in enumerate(results, start=1):
                title = item.get("title") or item.get("url", "")
                lines.append(f"[{idx}] {title}")
                if item.get("content"):
                    lines.append(f"    {item['content']}")
                if item.get("url"):
                    lines.append(f"    æ¥æº: {item['url']}")
                lines.append("")
        else:
            lines.append("âŒ æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æžœã€‚")

        if notices:
            lines.append("âš ï¸ æ³¨æ„äº‹é¡¹ï¼š")
            for notice in notices:
                if notice:
                    lines.append(f"- {notice}")

        return "\n".join(line for line in lines if line is not None)


# ä¾¿æ·å‡½æ•°

def search(query: str, backend: str = "hybrid") -> str:
    tool = SearchTool(backend=backend)
    return tool.run({"input": query, "backend": backend})  # type: ignore[return-value]


def search_tavily(query: str) -> str:
    tool = SearchTool(backend="tavily")
    return tool.run({"input": query, "backend": "tavily"})  # type: ignore[return-value]


def search_serpapi(query: str) -> str:
    tool = SearchTool(backend="serpapi")
    return tool.run({"input": query, "backend": "serpapi"})  # type: ignore[return-value]


def search_hybrid(query: str) -> str:
    tool = SearchTool(backend="hybrid")
    return tool.run({"input": query, "backend": "hybrid"})  # type: ignore[return-value]
